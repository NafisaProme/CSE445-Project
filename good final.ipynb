{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "g2MmrJT7jUEQ"
   },
   "outputs": [],
   "source": [
    "import math #mathematical computation\n",
    "import pandas as pd #dataframe\n",
    "# pd.set_option('max_rows', 10000)\n",
    "# pd.set_option('max_colwidth', 400)\n",
    "# pd.describe_option('max_colwidth')\n",
    "import numpy as np #mathematical computations\n",
    "import matplotlib.pyplot as plt #visualization\n",
    "import matplotlib\n",
    "import joblib #saving the model\n",
    "import seaborn as sns #visualization\n",
    "import json #exporting columns\n",
    "import pickle #saving the model\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz #Decision Tree Classifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, r2_score #Performance metrics\n",
    "\n",
    "from sklearn.linear_model import LinearRegression #Linear Regression\n",
    "from sklearn.linear_model import Lasso #Lasso Regression\n",
    "from sklearn.tree import DecisionTreeRegressor #Decision Tree Regression\n",
    "from sklearn.ensemble import RandomForestRegressor #Random Forest Regression\n",
    "# from xgboost import XGBRegressor # XGBoost Regression\n",
    "from sklearn.model_selection import train_test_split #Splitting the dataset into training and testing\n",
    "from sklearn.model_selection import ShuffleSplit #Random shuffling\n",
    "from sklearn.model_selection import cross_val_score #Score cross validation\n",
    "from sklearn.model_selection import cross_validate #Score cross validation\n",
    "from sklearn.model_selection import GridSearchCV #Hyper parameter tuning\n",
    "\n",
    "from statistics import stdev\n",
    "from warnings import simplefilter #Filtering warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "##showing all columns in output##\n",
    "\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w-S2UdavjXmh",
    "outputId": "852d6d27-3526-4502-d885-bcbbad54fbdd"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18636\\1649010829.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CSE445.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_bad_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'skip'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/content/drive')\n",
    "data = pd.read_csv('CSE445.csv', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "U1ZsHQAGji_Y",
    "outputId": "3cee15c5-3c3d-4c22-e5f8-de5e7d8b16a9"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13pLUa-0jsCN",
    "outputId": "4334b861-f066-465a-9960-4d7d9006b3ca"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Load your preprocessed dataset\n",
    "\n",
    "# Select features and target variable\n",
    "X = data.drop('Price', axis=1)  # Features (all columns except the target variable)\n",
    "y = data['Price']  # Target variable (price)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Decision Tree regressor\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R-squared:\", r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZRO5AnRijwkb",
    "outputId": "7d40c366-f971-4820-9241-aab4cd00200d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the dataset\n",
    "  # Replace 'laptop_prices.csv' with your actual dataset file name\n",
    "\n",
    "# Extract the features (independent variables) and target variable (dependent variable)\n",
    "X = data[['Brand', 'Processor Brand','Processor Model','Generation','RAM','RAM Type','Storage Capacity','Battery Capacity']]  # Replace 'feature1', 'feature2', ... with the actual feature column names\n",
    "y = data['Price']  # Replace 'price' with the actual target variable column name\n",
    "\n",
    "# Define the hyperparameters to tune and their potential values\n",
    "hyperparameters = {\n",
    "    'fit_intercept': [True, False],\n",
    "    # Add more hyperparameters and their potential values as needed\n",
    "}\n",
    "\n",
    "# Create an instance of the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Create GridSearchCV object with the model and hyperparameters\n",
    "grid_search = GridSearchCV(model, hyperparameters, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_hyperparameters = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "\n",
    "# Evaluate the best model using mean squared error (MSE)\n",
    "predicted_values = best_model.predict(X)\n",
    "mse = mean_squared_error(y, predicted_values)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IDPkx9C6khO5",
    "outputId": "0b39378f-b384-48df-92ab-e213f16198d2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the dataset\n",
    " # Replace 'laptop_prices.csv' with your actual dataset file name\n",
    "\n",
    "# Extract the features (independent variables) and target variable (dependent variable)\n",
    " # Replace 'feature1', 'feature2', ... with the actual feature column names\n",
    "X = data[['Brand', 'Processor Brand','Processor Model','Generation','RAM','RAM Type','Storage Capacity','Battery Capacity']] \n",
    "y = data['Price']  # Replace 'price' with the actual target variable column name\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an instance of the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data using the scaler fitted on the training data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create an instance of the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model on the scaled training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the scaled testing data\n",
    "predictions = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the mean squared error (MSE)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DOhagxS1l5VJ",
    "outputId": "2e233524-3b6d-45d5-c5e0-57c89311726e"
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PS3hvKInbBQ9"
   },
   "outputs": [],
   "source": [
    "df = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G2ws-emSbEDn",
    "outputId": "980498d6-3d77-48ae-fa49-610b3e994262"
   },
   "outputs": [],
   "source": [
    "data['Storage Capacity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ARriesMbIGl"
   },
   "outputs": [],
   "source": [
    "df['Storage Capacity'].replace(.0,3,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GrgkPprobhFk"
   },
   "outputs": [],
   "source": [
    "df['Processor Core'].replace(16.0,7,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qmv0VMnsblqo"
   },
   "outputs": [],
   "source": [
    "df = df.drop('Storage Capacity', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ED4cfvEUeWMN",
    "outputId": "095ea280-a4dc-49a6-9ec1-7c946cee2d22"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58SwgKOpeXpQ",
    "outputId": "7709f508-71ab-43da-a529-b284f50d54a9"
   },
   "outputs": [],
   "source": [
    "df['Graphics Memory'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BI4VTkf_ecKt"
   },
   "outputs": [],
   "source": [
    "df['Graphics Memory'].replace(16.0,5,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BySp1EdWepzU",
    "outputId": "728b2566-55c3-4426-bc16-515474498298"
   },
   "outputs": [],
   "source": [
    "df['Battery Capacity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xKkuVHhde49q"
   },
   "outputs": [],
   "source": [
    "df.to_csv('sec_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JfgCsnucfV4H",
    "outputId": "aa0514bf-d127-4800-8276-a451de7f77b2"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assume X and y are your feature matrix and target variable respectively\n",
    "# Update X and y with the relevant data from your dataset\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply feature scaling to the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Instantiate the Random Forest model with desired parameters\n",
    "random_forest = RandomForestRegressor(n_estimators=100, random_state=42)  # Specify the number of estimators\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_forest.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = random_forest.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R8N9uAdGf_ui",
    "outputId": "5f849d1e-707e-421f-ed04-849b37409806"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# Assume X and y are your feature matrix and target variable respectively\n",
    "# Update X and y with the relevant data from your dataset\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply feature scaling to the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Instantiate three Random Forest models with different configurations\n",
    "model1 = RandomForestRegressor(n_estimators=500, random_state=42)\n",
    "model2 = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "model3 = RandomForestRegressor(n_estimators=300, random_state=42)\n",
    "\n",
    "# Create an ensemble of the three models\n",
    "ensemble = VotingRegressor(estimators=[('model1', model1), ('model2', model2), ('model3', model3)])\n",
    "\n",
    "# Fit the ensemble model to the training data\n",
    "ensemble.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = ensemble.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6CsKCw-3g7gu",
    "outputId": "fd7bd556-eb15-4a26-c25c-5fda4429d6b2"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assume X and y are your feature matrix and target variable respectively\n",
    "# Update X and y with the relevant data from your dataset\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply feature scaling to the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Instantiate the Decision Tree model\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PO4L8cwHhQEn",
    "outputId": "88a9e979-6648-4f79-c322-5f17343f0e36"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assume X and y are your feature matrix and target variable respectively\n",
    "# Update X and y with the relevant data from your dataset\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply feature scaling to the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Instantiate the SVM model\n",
    "model = SVR()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p6akgzC4hcHN",
    "outputId": "99fee1ba-6786-447a-8ed9-87d9e9be8f53"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assume X and y are your feature matrix and target variable respectively\n",
    "# Update X and y with the relevant data from your dataset\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply feature scaling to the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Instantiate the KNN model\n",
    "model = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tPW5EbbVhnsH",
    "outputId": "775828f0-4419-4937-fefb-af70710fd2fe"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assume X and y are your feature matrix and target variable respectively\n",
    "# Update X and y with the relevant data from your dataset\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply feature scaling to the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Instantiate the Gradient Boosting model\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IVnZugPHhw_m",
    "outputId": "ddb1db27-f792-442f-aed4-02df8c24762c"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assume X and y are your feature matrix and target variable respectively\n",
    "# Update X and y with the relevant data from your dataset\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply feature scaling to the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Instantiate the SVR model\n",
    "model = SVR(kernel='rbf')\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p2NdbfqmiIdE",
    "outputId": "21d5a9e7-215e-4261-f4f7-c4562191f063"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Define the decision tree model\n",
    "decision_tree_model = DecisionTreeRegressor()\n",
    "\n",
    "# Define the random forest models\n",
    "random_forest_model_1 = RandomForestRegressor(n_estimators=100)\n",
    "random_forest_model_2 = RandomForestRegressor(n_estimators=200)\n",
    "\n",
    "# Fit the models on the training data\n",
    "decision_tree_model.fit(X_train, y_train)\n",
    "random_forest_model_1.fit(X_train, y_train)\n",
    "random_forest_model_2.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "decision_tree_predictions = decision_tree_model.predict(X_test)\n",
    "random_forest_predictions_1 = random_forest_model_1.predict(X_test)\n",
    "random_forest_predictions_2 = random_forest_model_2.predict(X_test)\n",
    "\n",
    "# Combine the predictions using averaging\n",
    "ensemble_predictions = (decision_tree_predictions + random_forest_predictions_1 + random_forest_predictions_2) / 3\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "mse = mean_squared_error(y_test, ensemble_predictions)\n",
    "mae = mean_absolute_error(y_test, ensemble_predictions)\n",
    "r2 = r2_score(y_test, ensemble_predictions)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kd3Afn79iwjs",
    "outputId": "badea2cd-03ce-4288-9bb2-bb36c51b6b61"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Create two decision tree models\n",
    "tree_model1 = DecisionTreeRegressor(random_state=42)\n",
    "tree_model2 = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Create two random forest models\n",
    "rf_model1 = RandomForestRegressor(random_state=42)\n",
    "rf_model2 = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train the decision tree models\n",
    "tree_model1.fit(X_train, y_train)\n",
    "tree_model2.fit(X_train, y_train)\n",
    "\n",
    "# Train the random forest models\n",
    "rf_model1.fit(X_train, y_train)\n",
    "rf_model2.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using each model\n",
    "tree_preds1 = tree_model1.predict(X_test)\n",
    "tree_preds2 = tree_model2.predict(X_test)\n",
    "rf_preds1 = rf_model1.predict(X_test)\n",
    "rf_preds2 = rf_model2.predict(X_test)\n",
    "\n",
    "# Combine the predictions from each model\n",
    "ensemble_preds = (tree_preds1 + tree_preds2 + rf_preds1 + rf_preds2) / 4\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "mse = mean_squared_error(y_test, ensemble_preds)\n",
    "mae = mean_absolute_error(y_test, ensemble_preds)\n",
    "r2 = r2_score(y_test, ensemble_preds)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I2a83RBLi81G",
    "outputId": "33b0de87-4416-46cb-a115-35f6ba975b5c"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create two decision tree regressors\n",
    "decision_tree1 = DecisionTreeRegressor()\n",
    "decision_tree2 = DecisionTreeRegressor()\n",
    "\n",
    "# Create five random forest regressors\n",
    "random_forest1 = RandomForestRegressor()\n",
    "random_forest2 = RandomForestRegressor()\n",
    "random_forest3 = RandomForestRegressor()\n",
    "random_forest4 = RandomForestRegressor()\n",
    "random_forest5 = RandomForestRegressor()\n",
    "\n",
    "# Fit the decision tree models\n",
    "decision_tree1.fit(X_train, y_train)\n",
    "decision_tree2.fit(X_train, y_train)\n",
    "\n",
    "# Fit the random forest models\n",
    "random_forest1.fit(X_train, y_train)\n",
    "random_forest2.fit(X_train, y_train)\n",
    "random_forest3.fit(X_train, y_train)\n",
    "random_forest4.fit(X_train, y_train)\n",
    "random_forest5.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the individual models\n",
    "dt1_predictions = decision_tree1.predict(X_test)\n",
    "dt2_predictions = decision_tree2.predict(X_test)\n",
    "\n",
    "rf1_predictions = random_forest1.predict(X_test)\n",
    "rf2_predictions = random_forest2.predict(X_test)\n",
    "rf3_predictions = random_forest3.predict(X_test)\n",
    "rf4_predictions = random_forest4.predict(X_test)\n",
    "rf5_predictions = random_forest5.predict(X_test)\n",
    "\n",
    "# Combine the predictions\n",
    "ensemble_predictions = (dt1_predictions + dt2_predictions + rf1_predictions +\n",
    "                        rf2_predictions + rf3_predictions + rf4_predictions + rf5_predictions) / 7\n",
    "\n",
    "# Calculate the evaluation metrics for the ensemble model\n",
    "mse = mean_squared_error(y_test, ensemble_predictions)\n",
    "mae = mean_absolute_error(y_test, ensemble_predictions)\n",
    "r2 = r2_score(y_test, ensemble_predictions)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cqIwltdvjMs6",
    "outputId": "6d77005e-ac03-4231-d8d5-8e757b262274"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the models\n",
    "decision_tree = DecisionTreeRegressor(random_state=42)\n",
    "random_forests = [RandomForestRegressor(random_state=42) for _ in range(10)]\n",
    "\n",
    "# Fit the decision tree model\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Fit the random forest models\n",
    "for i in range(len(random_forests)):\n",
    "    random_forests[i].fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using each model\n",
    "decision_tree_pred = decision_tree.predict(X_test)\n",
    "random_forests_pred = np.mean([model.predict(X_test) for model in random_forests], axis=0)\n",
    "\n",
    "# Combine the predictions\n",
    "ensemble_pred = (decision_tree_pred + random_forests_pred) / 2\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, ensemble_predictions)\n",
    "mae = mean_absolute_error(y_test, ensemble_predictions)\n",
    "r2 = r2_score(y_test, ensemble_predictions)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eY5X_isWjapP",
    "outputId": "7c2a9d68-2b52-4694-e137-f9bc18f988e7"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Assume X and y are your feature matrix and target variable respectively\n",
    "# Update X and y with the relevant data from your dataset\n",
    "\n",
    "# Create a list to store the individual models\n",
    "models = []\n",
    "\n",
    "# Train ten Random Forest models and add them to the list\n",
    "for _ in range(10):\n",
    "    # Create a Random Forest model\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=10)\n",
    "\n",
    "    # Train the model on the data\n",
    "    rf.fit(X, y)\n",
    "\n",
    "    # Add the trained model to the list\n",
    "    models.append(rf)\n",
    "\n",
    "# Make predictions using each individual model\n",
    "predictions = []\n",
    "for model in models:\n",
    "    pred = model.predict(X)\n",
    "    predictions.append(pred)\n",
    "\n",
    "# Combine the predictions using the average\n",
    "ensemble_pred = np.mean(predictions, axis=0)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "mse = mean_squared_error(y, ensemble_pred)\n",
    "mae = mean_absolute_error(y, ensemble_pred)\n",
    "r2 = r2_score(y, ensemble_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `predictions` and `y` contain the predicted and actual values, respectively\n",
    "for pred, actual in zip(ensemble_pred, y):\n",
    "    print(\"Predicted Price:\", pred, \"Actual Price:\", actual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJGQet90kQkG"
   },
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\mdmai\\Downloads\\sec_data.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(0)\n",
    "df_train, df_test = train_test_split(df, train_size = 0.8, test_size = 0.2, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Price', axis=1)\n",
    "y = df['Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.1)\n",
    "\n",
    "lasso.fit(X_train, y_train)\n",
    "y_pred = lasso.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")\n",
    "\n",
    "predicted_values = lasso.predict(X_test)\n",
    "\n",
    "for i, (prediction, actual) in enumerate(zip(y_pred, y_test)):\n",
    "   print(f\" {i+1}. Predicted price: {prediction:.2f}, Actual price: {actual:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred1 = rf.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred1)\n",
    "mae = mean_absolute_error(y_test, y_pred1)\n",
    "r2 = r2_score(y_test, y_pred1)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")\n",
    "for i, (prediction, actual) in enumerate(zip(y_pred1, y_test), start=1):\n",
    "    print(f\"Data Point {i}: Predicted Price: {prediction:.2f}, Actual Price: {actual:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha=0.1)\n",
    "\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "y_pred2 = ridge.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred2)\n",
    "mae = mean_absolute_error(y_test, y_pred2)\n",
    "r2 = r2_score(y_test, y_pred2)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")\n",
    "for i, (prediction, actual) in enumerate(zip(y_pred2, y_test), start=1):\n",
    "    print(f\"Data Point {i}: Predicted Price: {prediction:.2f}, Actual Price: {actual:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred4 = dt.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred4)\n",
    "mae = mean_absolute_error(y_test, y_pred4)\n",
    "r2 = r2_score(y_test, y_pred4)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")\n",
    "for i, (prediction, actual) in enumerate(zip(y_pred4, y_test), start=1):\n",
    "    print(f\"Data Point {i}: Predicted Price: {prediction:.2f}, Actual Price: {actual:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import GradientBoostingRegressor\n",
    "\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "y_pred5 = gb.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred5)\n",
    "r2 = r2_score(y_test, y_pred5)\n",
    "mae = mean_absolute_error(y_test, y_pred5)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")\n",
    "\n",
    "for i, (prediction, actual) in enumerate(zip(y_pred5, y_test), start=1):\n",
    "    print(f\"Data Point {i}: Predicted Price: {prediction:.2f}, Actual Price: {actual:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(df,open('df.pkl','wb'))\n",
    "pickle.dump(pipe,open('pipe.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
